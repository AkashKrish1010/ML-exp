import pandas as pd

# Read dataset
df = pd.read_csv("sports.csv")

# Separate features and target using drop()
X = df.drop('EnjoySport', axis=1).values
y = df['EnjoySport'].values

# Initialize S and G
S = list(X[0])  # Start with the first positive example
G = [['?' for _ in range(len(S))]]  # Most general hypothesis

# Consistency check
def consistent(h, x):
    return all(h[i] == x[i] or h[i] == '?' for i in range(len(h)))

# Loop over training examples
for i in range(len(X)):
    if y[i] == 'Yes':
        for j in range(len(S)):
            if S[j] != X[i][j]:
                S[j] = '?'
        G = [g for g in G if consistent(g, X[i])]
    else:
        new_G = []
        for g in G:
            for j in range(len(g)):
                if g[j] == '?':
                    for val in set(df.iloc[:, j]):
                        if val != X[i][j]:
                            new_h = g[:]
                            new_h[j] = val
                            if consistent(S, new_h):
                                new_G.append(new_h)
        G = new_G

# Print results
print("Most Specific Hypothesis (S):", S)
print("Most General Hypotheses (G):", G)




import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split

# Sample data
X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)
y = np.array([3, 6, 11, 18, 27, 38])  # Clearly nonlinear trend

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y)

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_score = linear_model.score(X_test, y_test)

# Polynomial Regression (degree 2)
poly_model = make_pipeline(PolynomialFeatures(2), LinearRegression())
poly_model.fit(X_train, y_train)
poly_score = poly_model.score(X_test, y_test)

# Plotting
plt.scatter(X, y, color='blue', label="Data")
plt.plot(X, linear_model.predict(X), color='red', label="Linear")
plt.plot(X, poly_model.predict(X), color='green', label="Polynomial (deg 2)")
plt.legend()
plt.title("Linear vs Polynomial Regression")
plt.show()

print("Linear R^2 Score:", linear_score)
print("Polynomial R^2 Score:", poly_score)

